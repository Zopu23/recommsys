# 2408.04211v2.pdf

MMREC: LLM Based Multi-Modal Recommender
System

1st Jiahao Tian
Georgia Institute of Technology
Atlanta, Georgia, USA
jtian83@gatech.edu

2nd Zhenkai Wang
The University of Texas at Austin
Austin, Texas, USA
kay.zhenkai.wang@utexas.edu

3rd Jinman Zhao
University of Toronto
Toronto, Ontario, Canada
jinman.zhao@mail.utoronto.ca

4th Zhicheng Ding
Columbia University
New York, NY, USA
zhicheng.ding@columbia.edu

Abstract—The importance of recommender systems is growing
rapidly due to the exponential increase in the volume of content
generated daily. This surge in content presents unique challenges
for designing effective recommender systems. Key among these
challenges is the need to effectively leverage the vast amounts
of natural language data and images that represent user pref-
erences. This paper presents a novel approach to enhancing
recommender systems by leveraging Large Language Models
(LLMs) and deep learning techniques. The proposed framework
aims to improve the accuracy and relevance of recommendations
by incorporating multi-modal information processing and by the
use of unified latent space representation. The study explores
the potential of LLMs to better understand and utilize natural
language data in recommendation contexts, addressing the limita-
tions of previous methods. The framework efficiently extracts and
integrates text and image information through LLMs, unifying
diverse modalities in a latent space to simplify the learning pro-
cess for the ranking model. Experimental results demonstrate the
enhanced discriminative power of the model when utilizing multi-
modal information. This research contributes to the evolving field
of recommender systems by showcasing the potential of LLMs
and multi-modal data integration to create more personalized
and contextually relevant recommendations.

Index Terms—Multi-Modality, Large Language Models, Rec-
ommender System, Deep Learning Recommendation Model,
Personalization, Imbalanced Dataset Modeling

I. INTRODUCTION

Recommender Systems (RS) have become an integral com-
ponent of modern digital ecosystems, playing a pivotal role in
personalizing user experiences across various domains such
as e-commerce, streaming services and more [1]–[3]. These
systems aim to suggest items that align with users’ tastes to
enchance user engagement. The foundations of the RS can be
traced back to collaborative filtering techniques, which lever-
age user-item interaction data to identify patterns and make
recommendations. Over time, these systems haveincorporated
more sophisticated approaches, including content-based filter-
ing, hybrid methods, and context-aware recommendations, to
address user data’s growing complexity and scale.

The development of machine learning and deep learning
has revolutionized nearly every field [4]–[14], including rec-
ommender systems. These systems now benefit from large-

scale models that can leverage vast amounts of data to ex-
tract complex relationships. Deep learning techniques, such
as neural collaborative filtering (NCF), convolutional neural
networks (CNNs), and recurrent neural networks (RNNs),
have been employed to enhance the accuracy and robustness
of Recommender System [15], [16]. These models benefit
from their ability to automatically learn feature representa-
tions from raw data, eliminating the need for manual feature
engineering and improving predictive performance. Moreover,
the use of attention mechanisms and transformer architectures
has further advanced the capabilities of deep learning-based
recommenders by allowing them to capture sequential and
contextual information better [2], [17].

Recently, Large Language Models (LLMs) like GPT-4 have
in understanding and generating
shown immense potential
human-like text. In recommender systems, vast amounts of
natural language data, such as user reviews and product infor-
mation, are rich in valuable insights [18], [19]. In this paper,
we propose a novel LLM-enhanced deep learning framework
with the following contributions:

• Developed a framework that efficiently extracts multi-
modal information like text and images, from LLMs

• Unifiied information from different

into same latent
space, simplifying the learning process for the ranking
model.

• Demonstrated how the use of multi-modal information
can further enhance the discriminative power of the
model, especially for improving false positive rate in the
case of the imbalanced dataset.

The structure of the paper is as follows: Section II introduces
the latest developments in recommender systems and LLMs.
Section III presents our proposed framework and its key
components. Section IV details the experimental setup and
analysis. Finally, Section V provides concluding remarks.

II. RELATED WORK

A. Recommender System

Earlier work on Recommender Systems(RS) did not in-
volve the extensive use of deep learning as seen in current

5
2
0
2

n
u
J

1
1

]
L
C
.
s
c
[

2
v
1
1
2
4
0
.
8
0
4
2
:
v
i
X
r
a

 
 
 
 
 
 
approaches. For specifics, one can refer to [20], which includes
over 100 techniques from before 2017.

RS can be broadly categorized into personalized [21], [22]
and group-based [23], [24] systems. Collaborative Filtering
(CF) stands out as a prevalent
technique. CF predicts a
user’s preferences or opinions by leveraging the collective
insights from a large user base. Notable implementations
include memory-based CF approaches such as those presented
in [25] and [26], which utilize vector representations. In
recent years, the integration of graph neural networks like
GraphSAGE [27], and others have significantly enhanced
model-based CF methods. These models have been exten-
sively applied across various domains, with notable success
in music, Point of Interest (POI), and book recommendations
[28] [29], [30]. For instance, the JODIE [28] model has been
influential in music recommendation, while Multi-GCCF [29],
and LightGCN [30] have shown promising results in POI and
book recommendation scenarios. Among these, LightGCN has
emerged as a classic model in the RS field. The effectiveness
in RS has been a subject of debate. For
of review text
example, [31] argued that not all parts of reviews hold equal
importance, leading them to propose an Aspect-based Neural
Recommender (ANR) that focuses on more granular feature
[32] employed capsule
representations of items. Similarly,
neural networks to extract specific viewpoints and aspects from
user and item reviews. Furthermore,
[33] developed a dual-
encoder system using CNNs, one for encoding news and the
other for learning user profiles based on their interaction with
clicked news.

B. Large Language Models Reasoning

LLMs have demonstrated remarkable reasoning capabil-
there has been a trend towards
ities [34], [35]. Recently,
[36] employs
using LLMs for traditional tasks. For instance,
in-context
learning on GPT-3 for Relation Extraction(RE),
achieving state-of-the-art (SOTA) performance on multiple test
sets. [37] adapts LLMs to the Named Entity Recognition
(NER) task, aiming to bridge the gap between sequence
labeling and text generation. This adaptation demonstrates
how LLMs can be fine-tuned or prompted in innovative
ways to handle tasks traditionally outside their direct training
objectives.
[38] investigate the capabilities of LLMs in zero-
shot information extraction scenarios, specifically examining
the performance of ChatGPT in the NER task. By focusing on
zero-shot learning, the study investigates ChatGPT’s ability to
identify and classify named entities within text and without
any task-specific training data or fine-tuning.
[39] conducted
the ability of LLMs to generate new financial signals. LLMs
have also been employed for other tasks such as text summa-
rization [40] and sentiment analysis [41].

C. LLM for Recommender Systems

LLMs have demonstrated remarkable reasoning capabili-
ties [34], [35], [39], [42], [43]. Recent efforts in the domain
of recommender systems have increasingly focused on the
utilization of Language Models [44]–[46]. [47] utilizes LLMs

as the interface for recommender systems, facilitating multi-
round recommendations. This enhances both the interactivity
[48] proposed a three-
and the explainability of the system.
step prompting strategy that substantially surpasses traditional
simple prompting techniques in zero-shot settings.
[49]
preprocess users’ instructions and traditional feedback, such
as clicks, using an instructor module to generate tailored
guidance.
[50] conduct an evaluation to assess off-the-shelf
LLMs for RS, analyzing them from point-wise, pair-wise, and
list-wise perspectives

III. METHODOLOGY

Our proposed model leverages deep learning techniques and
the advanced reasoning capabilities provided by large language
models (LLMs) to enhance the performance of the ranking
model. We hypothesize that the summarization power of LLMs
can significantly improve the discriminative capabilities of
the ranking model,
leading to more accurate and relevant
recommendations.

A. DLRM and the base model

DLRM is a robust framework that leverages deep learning
techniques for recommendation tasks [51]. DLRM has proven
to be highly effective in personalization and recommendation
scenarios, such as click-through rate (CTR) prediction. For
a comprehensive understanding of the technical intricacies of
Deep Learning Recommendation Models (DLRM), readers are
encouraged to consult the original research paper.

In the baseline model, we process the textual information
contained in user reviews by converting each text review into
an embedding using the sentence transformer. Specifically,
we use MiniLM-L6-v2 model for all our experiments [52].
We then take the element-wise average across all dimensions
to create user or business features. Similarly, each image
contained in the user reviews or associated with a particular
business is transformed into continuous data using ResNet50.
Specifically, we extract the second-to-last layer to represent
the images, capturing rich feature representations.

B. LLM summarization

To leverage the summarizing power of large language
models (LLMs), we propose various methods to enhance the
features fed into our model. In this section, we explain how the
LLM-enhanced DLRM differs from the base model presented
above.

• Dense Features: In addition to the continuous features
used in the base model (e.g., the number of reviews
a restaurant received, average rating), we utilize the
LLM’s reasoning ability to extract pricing information
from user reviews. This enriched feature set provides
a more comprehensive understanding of the restaurant
being scored.

• Sparse Features: Instead of applying an element-wise
average across embeddings from all textual reviews or
images, we use the LLM to process and summarize the
most important information from all reviews, obtaining

an embedding for this summary alone. For images, we
leverage the LLM’s multimodal capabilities to interpret
and summarize the information contained in the images,
converting them into textual descriptions. This textual
information is then processed in a similar manner to the
reviews.

This approach offers several advantages:
• Reduction of Noise: By summarizing the most important
information, we ensure that only relevant data is fed
into the model, preventing irrelevant or noisy information
from diluting important signals.

• Unified Embedding Technique: Since images are con-
verted into textual descriptions, both reviews and images
use the same embedding technique to transform them
into continuous data. This ensures that features from
different modalities are projected into the same latent
space, enhancing the model’s ability to understand and
utilize the combined information effectively.

Besides the differences mentioned above, as shown in
Figure 1, we also introduce an additional sparse feature into
the model. Using the LLM, we categorize each restaurant into
one of 11 categories. This categorical feature is then fed into
the feature interaction module after the embedding layer.

C. Dimension reduction

To mitigate the risk of overfitting caused by the high-
dimensional outputs of both the sentence transformer (384
dimensions) and ResNet50 (2048 dimensions), we propose an
upstream model for dimensionality reduction. This approach
preserves meaningful information while addressing the poten-
tial increase in model parameters. Our method involves the
following steps:

• Concatenate embeddings from both the text encoder and

image encoder into a single tensor.

• Feed the tensor through a Multi-Layer Perceptron (MLP).
• The MLP outputs the probability of the outcome of

interest (e.g., a positive review).

Importantly, we apply the same MLP used in training to the
embeddings during the testing phase. This approach ensures
effective dimensionality reduction while retaining the most
crucial information for prediction. By implementing this tech-
nique, we balance model complexity and predictive power,
enhancing the overall the recommender system performance.

IV. EXPERIEMENT

In this study, we utilized a comprehensive dataset tailored
for restaurant reviews analysis. This data is published in Kag-
gle1 and it is collected from Google reviews [53]. This dataset
comprises user-generated reviews for various restaurants.

A. Parameter and Configuration

To evaluate the model’s performance under different condi-
tions, We experimented with various dropout rates [0.1, 0.3,

1https://www.kaggle.com/

0.5] and applied different weighted loss functions (basic and
square root) to address data imbalance.

• Basic:

• Square root:

W label = 1 −

N umlabel
N umtotal

(cid:114)

W label =

1 −

N umlabel
N umtotal

(1)

(2)

We used a learning rate of 0.01 and applied early stopping
after 300 epochs when the false positive rate showed no
improvement for 50 epochs. We repeated each parameter set
evaluation five times.

TABLE I
PERFORMANCE OF BEST MODEL AGAINST TRAINING SET

model

wgted loss

dropout

proposed

basic

sqrt root

baseline

basic

sqrt root

proposed-text1basic

sqrt root

proposed-image2basic

sqrt root

0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50

accuracy

fp rate

loss

91.62% 2.02% 2.7
4.08
88.11%
4.14%
5.28
86.06%
7.06%
4.36%
95.95%
4.36
13.69% 6.35
94.14%
18.87% 9.19
91.95%
26.58% 6.35
92.51%
27.82% 6.82
92.39%
28.27% 6.97
92.23%
29.01% 10.46
94.12%
31.02% 11.07
93.97%
33.49% 11.54
94.06%
0.7%
94.69%
1.74
2.68%
87.78%
3.76
4.31%
83.2%
5.35
3.67%
97.38%
2.88
6.09
8.95%
93.98%
24.56% 8.65
92.99%
8.77%
69.32%
8.14
12.38% 9.45
63.52%
18.25% 10.51
60.33%
54.93% 13.68
90.26%
62.06% 16.21
89.47%
71.56% 18.22
88.57%

B. Data Pre-processing

Our baseline model utilizes dense features and embedding
features to predict the review rating, where we exclude the
current review to avoid bias in generating user and business
features, ensuring that the current user’s or business’s review
does not influence the feature construction. Weuse the entire
training dataset to construct testing features.

• Dense Features:

– Total number of reviews received by this business.
– Average rating of all reviews by this user
– Average rating of this business

1This model is based on the proposed model but for the embedding features,

retains only text review

2This model is based on the proposed model but for the embedding features,

retains only image review

Fig. 1. LLM enhanced DLRM for the restaurant recommendation task

TABLE II
PERFORMANCE OF BEST MODEL AGAINST TESTING SET

model

wgted loss

dropout

proposed

basic

sqrt root

baseline

basic

sqrt root

proposed-text1basic

sqrt root

proposed-image2
basic

sqrt root

0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50
0.10
0.30
0.50

accuracy

fp rate

loss

27.22% 50.18
85.27%
84.02%
20.84% 30.66
83.48% 18.16% 15.96
38.68% 66.51
88.05%
36.42% 49.68
89.15%
31.82% 23.76
89.02%
31.80% 9.32
91.36%
31.74% 7.66
91.89%
31.79% 7.64
91.83%
35.26% 14.57
92.96%
93.26%
35.66% 12.62
93.47% 37.58% 12.59
38.68% 63.91
84.17%
36.03
26.8%
81.59%
19.09% 24.16
79.1%
48.84% 88.24
86.53%
40.9%
87.01%
50.87
44.66% 36.05
88.15%
38.53% 34.67
59.8%
32.68% 25.8
58.15%
28.3%
57.84%
21.97
76.23% 49.11
84.92%
76.08% 37.52
85.79%
79.72% 28.67
86.53%

Compared to the baseline model, we add new dense feature:
Price Tag, and a sparse Feature: Restaurant Category, into the
proposed model, transform all embedding features through
prompting engineering with GPT 3.5-turbo-1106 model and
multi-modal model.

• Dense Features:

Fig. 2. LLM user summary example.

• Embedding Features:

– User Review Text Feature: All review written by
the same user are independently converted into 384-
dimensional embedding vectors through sentence
transformer,
then apply average pooling to get a
single 1x384 vector.

– Business Review Text Feature: Similarly, process

reviews for same business into 1 x 384 vector.

– Review Image Feature: Firstly,

image into
a pre-trained reset-50 model, then extract features
from the second-to-last layer. Each image generates
a 1x2048-dimensional embedding vector then apply
average pooling to single vector.

input

– Finally, we concatenate these 3 features, process with
a upstream model to reduce its dimension to 32.

– Price Tag Feature: Use the prompt: “Can you tell
me if the price is over-rice, fair price, low price from

Below are reviews of a single user for multiple restaurants, can you summarize this user?1.Omg the tomato sauce is everything, in the meatball appetizer, pizza & as a dip for that scratch-made focaccia. Farm-fresh salad. A variety of artisan toppings. Ask for the chili oil! Goes great with the focaccia bread2.First time around last year, we stuck to eggs and Benedict, which were okay not outstanding. Ours included bleskiver, a delightful Danish pancake donut, crepe, and potato pancake with German sausage. The bleskiver is fluffy yet yeasty but not too sweet.3.My favorite is the zeppole. I'd come here just for pasta fagiole & donuts…This user seems to be a food enthusiast who enjoys trying a variety of dishes at different restaurants. They have a discerning palate and are able to provide detailed feedback on the food they have tried, including specific recommendations and critiques. They appreciate a range of cuisines, from Italian to Indian to American, and seem to have a particular fondness for unique and flavorful dishes. They also value the quality of ingredients and the overall dining experience, including the atmosphere and service.reviews for this restaurant. Give me just the category
”. With post-processing, we generate a price tag
categorized as fair price, overpriced, cheap price, or
none (if no clean indication of price level in reviews).

• Sparse Features:

– Restaurant Category Feature: Use prompt “can
you tell me what kind of restaurant this is from
these reviews for the restaurant. Return me in this
format:’type’”. There are 179 distinct types and the
maximum number of subtypes for a restaurant is 11.
In the pre-processing step, all subtype tensors were
padded to the length of 11, and the padding value is
set to 179 (i.e. embedding table contains 180 distinct
values and the last one is padding idx).

• Embedding Features with LLM:

– Get a summary of review with prompts shown in
Fig 2 to summarize all reviews written by the same
user, then convert the summary into an embedding
vector representing the user. Similarly, get the em-
bedding vector for a single business. We concatenate
the these two review summary features into one big
vector, then passed through an upstream model to
reduce vector dimensionality to 32.

– We rely on a multi-modal model (BLIP 2) to pro-
duce one description sentence for images through
unconditional image captioning as shown in Fig 3.
Transformed sentence into an embedding vector, then
apply average pooling on all
images’ vecotr and
get one vector, which is finally passed through an
upstream model to reduce its dimensionality to 32.

– Concatenating the text and image vector

Fig. 3. Using BLIP-2 to perform unconditional image captioning on restaurant
review image

C. Result

• Compared to the baseline model, the proposed model
achieves a much better false positive rate in both the train
set and the test set as shown in Table 1. The best training
set false positive rate is around 2%.

rate while accuracy is 83.48% we obtain a 19.4%
improvement in the false positive rate at the expense
of 10% decrease in accuracy

• A comprehensive ablation study is conducted to inves-
tigate the efficacy of different modalities in proposed
model. The results revealed a notable regression in both
overall accuracy and false positive rate, with the lat-
ter showing a more pronounced decline. This finding
suggests that both image and text modalities contribute
significantly to enhancing the model’s overall perfor-
mance by providing distinct signals. These modalities
prove particularly valuable in determining the alignment
between items and user interests. The synergistic effect
of combining visual and textual information appears to
be crucial in reducing false positives and improving the
model’s discriminative power.

D. Analysis

In the context of ranking and recommendation, a high
false positive rate is unacceptable. In most practical RS, top
1 accuracy becomes less important and top N accuracy is
high enough. A lower false positive rate ensures that
the
recommendations are more aligned with the users’ tastes. The
baseline model focuses on accuracy due to imbalanced data but
struggles with false sample identification, making the proposed
model’s lower false positive rate more valuable.

The significant reduction in the false positive rate observed
in the proposed model can be attributed to the powerful ability
of Large Language Models (LLMs) in summarizing reviews.
In addition, LLMs are good at extracting and emphasizing
critical and repeated information in various reviews. This sum-
marization power ensures that the model captures the essential
features that distinguish different users and restaurants, while,
the baseline model take average of the embedding vectors.
This method tends to dilute the information because it treats
all reviews equally, regardless of their quality or relevance,
hence introduce more nosie and halt performance.

The proposed model

leverages the multimodal model
(BLIP2) and its description ability to identify multiple food
items, help to discriminate between various users and restau-
rants. By contrast, the baseline model relies on the image clas-
sification model(resnet), which has limitations in identifying
multiple objects within the image, especially when dealing
with multiple types, and fail to capture the semantic meaning
within images, making the extracted signals less powerful.

Our ablation study shows that both LLM and multimodal
features provide critical information for predicting user pref-
erences. Removing either modality results in a performance
drop, indicating that both text and image reviews contribute
valuable insights

V. CONCLUSION

• Given Table 2, the best model for test set false positive
rate is the proposed model with basic weighted loss
and 0.5 dropout rate, achieving 18.16% false positive

In this paper, we have proposed an innovative framework
that harnesses the reasoning and summarization capabilities
information effectively,
of LLMs to process multi-modal

demonstrating the significant potential of integrating multi-
modal data to enhance the performance of deep learning-based
recommender systems, particularly in scenarios involving im-
balanced datasets.

This novel method convert image-based information into
textual data, allowing both to be processed by same text
encoder ˙Consequently, both image-derived and text-based fea-
tures are represented in the same latent space, ensuring a more
cohesive and comprehensive input.

Our findings show that LLM-generated signals greatly
improve model performance, where enhancement is mainly
driven by two factors:

• The ability to extract valuable insights from negative
information for

reviews, which often contain critical
recommendation systems.

• LLMs distill essential information, avoiding the dilution

common in traditional averaging approaches.

The improved performance underscores the potential of
LLMs and multi-modal models in enchancing recommender
systems. More accurate and effective recommendations are
achieved by leveraging the contextual understanding and dis-
criminative capabilities of these models.

REFERENCES

[1] H. Guo, R. Tang, Y. Ye, Z. Li, and X. He, “Deepfm: a factorization-
machine based neural network for ctr prediction,” arXiv preprint
arXiv:1703.04247, 2017.

[2] G. Zhou, X. Zhu, C. Song, Y. Fan, H. Zhu, X. Ma, Y. Yan, J. Jin, H. Li,
and K. Gai, “Deep interest network for click-through rate prediction,”
in Proceedings of the 24th ACM SIGKDD international conference on
knowledge discovery & data mining, 2018, pp. 1059–1068.

[3] B. Yin, J. Xie, Y. Qin, Z. Ding, Z. Feng, X. Li, and W. Lin,
“Heterogeneous knowledge fusion: A novel approach for personalized
recommendation via llm,” in Proceedings of the 17th ACM Conference
on Recommender Systems, 2023, pp. 599–601.

[4] K. He, X. Zhang, S. Ren, and J. Sun, “Identity mappings in deep residual
networks,” in Computer Vision–ECCV 2016: 14th European Conference,
Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part
IV 14. Springer, 2016, pp. 630–645.

[5] X. Yang, Y. Kang, and X. Yang, “Retargeting destinations of passive
props for enhancing haptic feedback in virtual reality,” in 2022 IEEE
Conference on Virtual Reality and 3D User Interfaces Abstracts and
Workshops (VRW).

IEEE, 2022, pp. 618–619.
[6] J. Tian and M. D. Porter, “Changing presidential approval: Detecting
and understanding change points in interval censored polling data,” Stat,
vol. 11, no. 1, p. e463, 2022.

[7] ——, “Time of week intensity estimation from partly interval censored
data with applications to police patrol planning,” Journal of Applied
Statistics, pp. 1–19, 2024.

[8] M. V. Koroteev, “Bert: a review of applications in natural language
processing and understanding,” arXiv preprint arXiv:2103.11943, 2021.
[9] A. Koch, J. Tian, and M. D. Porter, “Criminal consistency and dis-
tinctiveness,” in 2020 Systems and Information Engineering Design
Symposium (SIEDS).
[10] J. Zhao, G. Penn,

IEEE, 2020, pp. 1–3.
and H. Ling,

realization with
the Fifteenth Workshop on Graph-
GGNNs,” in Proceedings of
for Natural Language Processing (TextGraphs-
Based Methods
15), A. Panchenko, F. D. Malliaros, V. Logacheva, A.
Jana,
D. Ustalov, and P. Jansen, Eds. Mexico City, Mexico: Association for
Computational Linguistics, Jun. 2021, pp. 115–124. [Online]. Available:
https://aclanthology.org/2021.textgraphs-1.11

“Structural

[11] Z. Ding, J. Tian, Z. Wang, J. Zhao, and S. Li, “Semantic understanding
and data imputation using large language model to accelerate recom-
mendation system,” arXiv preprint arXiv:2407.10078, 2024.

[12] Y. Tao, Y. Jia, N. Wang, and H. Wang, “The fact: Taming latent factor
models for explainability with factorization trees,” in Proceedings of the
42nd international ACM SIGIR conference on research and development
in information retrieval, 2019, pp. 295–304.

[13] Y. Tao, Z. Wang, H. Zhang, and L. Wang, “Nevlp: Noise-robust
framework for efficient vision-language pre-training,” arXiv preprint
arXiv:2409.09582, 2024.

[14] Y. Zhu, C. Honnet, Y. Kang, J. Zhu, A. J. Zheng, K. Heinz, G. Tang,
L. Musk, M. Wessely, and S. Mueller, “Demonstration of chromocloth:
Re-programmable multi-color textures through flexible and portable light
source,” in Adjunct Proceedings of the 36th Annual ACM Symposium on
User Interface Software and Technology, 2023, pp. 1–3.

[15] H.-T. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye,
G. Anderson, G. Corrado, W. Chai, M. Ispir et al., “Wide & deep
learning for recommender systems,” in Proceedings of the 1st workshop
on deep learning for recommender systems, 2016, pp. 7–10.

[16] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, “Neural col-
laborative filtering,” in Proceedings of the 26th international conference
on world wide web, 2017, pp. 173–182.

[17] Q. Pi, G. Zhou, Y. Zhang, Z. Wang, L. Ren, Y. Fan, X. Zhu, and K. Gai,
“Search-based user interest modeling with lifelong sequential behavior
data for click-through rate prediction,” in Proceedings of the 29th ACM
International Conference on Information & Knowledge Management,
2020, pp. 2685–2692.

[18] L. Zheng, V. Noroozi, and P. S. Yu, “Joint deep modeling of users and
items using reviews for recommendation,” in Proceedings of the tenth
ACM international conference on web search and data mining, 2017,
pp. 425–434.

[19] S. S. Li and E. Karahanna, “Online recommendation systems in a b2c
e-commerce context: a review and future directions,” Journal of the
association for information systems, vol. 16, no. 2, p. 2, 2015.

[20] K. Haruna, M. Akmar Ismail, S. Suhendroyono, D. Damiasih, A. C.
Pierewan, H. Chiroma, and T. Herawan, “Context-aware recommender
system: A review of recent developmental process and future research
direction,” Applied Sciences, vol. 7, no. 12, 2017. [Online]. Available:
https://www.mdpi.com/2076-3417/7/12/1211

[21] C. Wu, S. Liu, Z. Zeng, M. Chen, A. Alhudhaif, X. Tang, F. Alenezi,
N. Alnaim, and X. Peng, “Knowledge graph-based multi-context-aware
recommendation algorithm,” Information Sciences, vol. 595, pp. 179–
194, 2022.

[22] J. Zheng, J. Mai, and Y. Wen, “Explainable session-based recommen-
dation with meta-path guided instances and self-attention mechanism,”
in Proceedings of the 45th International ACM SIGIR Conference on
Research and Development in Information Retrieval, 2022, pp. 2555–
2559.

[23] S. Zan, Y. Zhang, X. Meng, P. Lv, and Y. Du, “Uda: A user-difference
attention for group recommendation,” Information Sciences, vol. 571,
pp. 401–417, 2021.

[24] M. Gao, Y. Wei, Z. Li, B. Huang, C. Zheng, and A. Mulati, “A survey
of machine learning algorithms for defective steel plates classification,”
in International Conference on Computing, Control and Industrial
Engineering. Springer, 2024, pp. 467–476.

[25] C.-M. Chen, C.-J. Wang, M.-F. Tsai, and Y.-H. Yang, “Collaborative
similarity embedding for recommender systems,” in The World Wide
Web Conference, 2019, pp. 2637–2643.

[26] O. Barkan, R. Hirsch, O. Katz, A. Caciularu, and N. Koenigstein,
“Anchor-based collaborative filtering,” in Proceedings of the 30th ACM
International Conference on Information & Knowledge Management,
2021, pp. 2877–2881.

[27] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation
learning on large graphs,” Advances in neural information processing
systems, vol. 30, 2017.

[28] S. Kumar, X. Zhang, and J. Leskovec, “Predicting dynamic embedding
trajectory in temporal interaction networks,” in Proceedings of the 25th
ACM SIGKDD international conference on knowledge discovery & data
mining, 2019, pp. 1269–1278.

[29] J. Sun, Y. Zhang, C. Ma, M. Coates, H. Guo, R. Tang, and X. He, “Multi-
graph convolution collaborative filtering,” in 2019 IEEE International
Conference on Data Mining (ICDM).

IEEE, 2019, pp. 1306–1311.

[30] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, and M. Wang, “Lightgcn:
Simplifying and powering graph convolution network for recommenda-
tion,” in Proceedings of the 43rd International ACM SIGIR conference
on research and development in Information Retrieval, 2020, pp. 639–
648.

[31] J. Y. Chin, K. Zhao, S. Joty, and G. Cong, “Anr: Aspect-based neural
recommender,” in Proceedings of the 27th ACM International conference
on information and knowledge management, 2018, pp. 147–156.
[32] C. Li, C. Quan, L. Peng, Y. Qi, Y. Deng, and L. Wu, “A capsule
network for recommendation and explaining what you like and dislike,”
in Proceedings of the 42nd international ACM SIGIR conference on
research and development in information retrieval, 2019, pp. 275–284.
[33] C. Wu, F. Wu, M. An, J. Huang, Y. Huang, and X. Xie, “Npa: neural
news recommendation with personalized attention,” in Proceedings of
the 25th ACM SIGKDD international conference on knowledge discov-
ery & data mining, 2019, pp. 2576–2584.

[34] C. Zhao, X. Jia, V. Viswanathan, T. Wu, and G. Neubig, “Self-guide:
Better task-specific instruction following via self-synthetic finetuning,”
2024. [Online]. Available: https://arxiv.org/abs/2407.12874

[35] N. He, H. Lai, C. Zhao, Z. Cheng, J. Pan, R. Qin, R. Lu,
R. Lu, Y. Zhang, G. Zhao, Z. Hou, Z. Huang, S. Lu, D. Liang,
and M. Zhan, “Teacherlm: Teaching to fish rather
than giving
the fish,
[Online]. Available:
https://arxiv.org/abs/2310.19019

language modeling likewise,” 2024.

[51] M. Naumov, D. Mudigere, H.-J. M. Shi, J. Huang, N. Sundaraman,
J. Park, X. Wang, U. Gupta, C.-J. Wu, A. G. Azzolini et al., “Deep
learning recommendation model for personalization and recommenda-
tion systems,” arXiv preprint arXiv:1906.00091, 2019.

[52] W. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, “Minilm:
Deep self-attention distillation for task-agnostic compression of pre-
trained transformers,” in Proceedings of the 34th International Confer-
ence on Neural Information Processing Systems, 2020, pp. 5776–5788.
[53] H. Wang, “Google restaurants rating [recommendation system],” 2023,
[Online]. Available: https://www.kaggle.com/

accessed: 2024-05-20.
datasets/hwwang98/google-restaurants

In-context

learning for

[36] Z. Wan, F. Cheng, Z. Mao, Q. Liu, H. Song, J. Li, and S. Kurohashi,
relation extraction using large
“GPT-RE:
language models,” in Proceedings of
the 2023 Conference on
Empirical Methods in Natural Language Processing, H. Bouamor,
J. Pino, and K. Bali, Eds. Singapore: Association for Computational
Linguistics, Dec. 2023, pp. 3534–3547. [Online]. Available: https:
//aclanthology.org/2023.emnlp-main.214

[37] S. Wang, X. Sun, X. Li, R. Ouyang, F. Wu, T. Zhang, J. Li, and G. Wang,
“Gpt-ner: Named entity recognition via large language models,” 2023.
[38] T. Xie, Q. Li, J. Zhang, Y. Zhang, Z. Liu, and H. Wang, “Empirical
study of zero-shot NER with ChatGPT,” in Proceedings of the 2023
Conference on Empirical Methods in Natural Language Processing,
Singapore: Association
H. Bouamor, J. Pino, and K. Bali, Eds.
for Computational Linguistics, Dec. 2023, pp. 7935–7956. [Online].
Available: https://aclanthology.org/2023.emnlp-main.493

[39] Y. Wang, J. Zhao, and Y. Lawryshyn, “GPT-signal: Generative AI for
semi-automated feature engineering in the alpha research process,” in
Proceedings of the Eighth Financial Technology and Natural Language
Processing and the 1st Agent AI for Scenario Planning, C.-C. Chen,
T. Ishigaki, H. Takamura, A. Murai, S. Nishino, H.-H. Huang, and
H.-H. Chen, Eds.
Jeju, South Korea: -, 3 Aug. 2024, pp. 42–53.
[Online]. Available: https://aclanthology.org/2024.finnlp-2.4

[40] T. Goyal, J. J. Li, and G. Durrett, “News summarization and evaluation

in the era of gpt-3,” 2023.

[41] X. Sun, X. Li, S. Zhang, S. Wang, F. Wu, J. Li, T. Zhang, and G. Wang,

“Sentiment analysis through llm negotiations,” 2023.

[42] J. Zhang, X. Wang, W. Ren, L. Jiang, D. Wang, and K. Liu, “Ratt: A
thought structure for coherent and correct llm reasoning,” 2024.
[43] J. Zhang, F. Mo, X. Wang, and K. Liu, “Thought space explorer:
Navigating and expanding thought space for large language model
reasoning,” 2024. [Online]. Available: https://arxiv.org/abs/2410.24155
[44] Y. Hou, S. Mu, W. X. Zhao, Y. Li, B. Ding, and J.-R. Wen, “Towards
universal sequence representation learning for recommender systems,”
in Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, 2022, pp. 585–593.

[45] X. Wang, K. Zhou, J.-R. Wen, and W. X. Zhao, “Towards unified
conversational recommender systems via knowledge-enhanced prompt
learning,” in Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining, 2022, pp. 1929–1937.

[46] Y. Yuan, Y. Huang, Y. Ma, X. Li, Z. Li, Y. Shi, and H. Zhou,
“Rhyme-aware chinese lyric generator based on gpt,” arXiv preprint
arXiv:2408.10130, 2024.

[47] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-
rec: Towards interactive and explainable llms-augmented recommender
system,” arXiv preprint arXiv:2303.14524, 2023.

[48] L. Wang and E.-P. Lim, “Zero-shot next-item recommendation using
large pretrained language models,” arXiv preprint arXiv:2304.03153,
2023.

[49] W. Wang, X. Lin, F. Feng, X. He, and T.-S. Chua, “Generative rec-
ommendation: Towards next-generation recommender paradigm,” arXiv
preprint arXiv:2304.03516, 2023.

[50] S. Dai, N. Shao, H. Zhao, W. Yu, Z. Si, C. Xu, Z. Sun, X. Zhang, and
J. Xu, “Uncovering chatgpt’s capabilities in recommender systems,” in
Proceedings of the 17th ACM Conference on Recommender Systems,
2023, pp. 1126–1132.

